---
# Initial manual preparation (not needed with a c9s cloud image on PSI):
# - Create user, add to group wheel: useradd -m -G wheel stack
# - Set password for new user: passwd stack
# - Let users of wheel group use sudo without password: visudo
# - Copy local ssh key to remote machine: ssh-copy-id stack@<host>
- name: Upgrade all packages
  ansible.builtin.dnf:
    name: "*"
    nobest: True
    state: latest
  become: yes
  when: ansible_os_family == 'RedHat'
  tags: install

- name: Install required packages
  ansible.builtin.package:
    name:
      - ansible-core
      - gcc
      - git-core
      - make
      - podman
      - python3
      - python3-pip
      - https://github.com/txn2/kubefwd/releases/download/1.22.5/kubefwd_amd64.rpm
    state: latest
  become: yes
  tags: install

- name: Install some extra packages
  ansible.builtin.package:
    name:
      - bash-completion
      - delve
      - tmux
      - vim
    state: latest
  become: yes
  tags: install

- name: Pip install pre-commit as user
  ansible.builtin.pip:
    name:
      - pre-commit
    extra_args: --user
  tags: install

- name: Clone operators using Git
  ansible.builtin.git: "{{ item }}"
  with_items: "{{ operators_git_repos }}"
  tags: git

- name: Create ~/pull-secret.txt
  template:
    src: pull-secret.txt.j2
    dest: "~/pull-secret.txt"
  tags: [crc, pre-config]

- name: Ensure ~/.config/openstack directory exists
  ansible.builtin.file:
    path: ~/.config/openstack
    state: directory
    mode: '0755'
  tags: [crc, pre-config]

- name: Set up ~/.config/openstack/clouds.yaml
  copy:
    src: clouds.yaml
    dest: ~/.config/openstack/clouds.yaml
  tags: [crc, pre-config]

- name: Create devsetup using make (may take 30 minutes or more)
  make:
    target: crc
    params:
      CPUS: "{{ make_crc_cpus }}"
      MEMORY: "{{ make_crc_memory }}"
      DISK: "{{ make_crc_disk }}"
    chdir: "~/install_yamls/devsetup"
  tags: crc

- name: Run make download_tools
  make:
    target: download_tools
    chdir: "~/install_yamls/devsetup"
  tags: crc

- name: Create symbolic link for kubectl
  file:
    src: ~/.crc/bin/oc/oc
    dest: ~/.crc/bin/oc/kubectl
    state: link
  tags: crc

- name: Create devsetup using make
  shell:
    cmd: |
      set +ex
      eval $(crc oc-env)
      oc login -u kubeadmin -p 12345678 https://api.crc.testing:6443
      make crc_storage
      make input
    chdir: "~/install_yamls"
  tags: crc

- name: Run make crc_attach_default_interface
  shell:
    cmd: |
      set +ex
      eval $(crc oc-env)
      oc login -u kubeadmin -p 12345678 https://api.crc.testing:6443
      make attach_default_interface_cleanup
      make crc_attach_default_interface
      exit 0
    chdir: "~/install_yamls/devsetup"
  tags: crc

# Without this there could be image pull limit errors when deploying rabbitmq
# Based on https://docs.openshift.com/container-platform/4.13/openshift_images/managing_images/using-image-pull-secrets.html#images-update-global-pull-secret_using-image-pull-secrets
- name: Add docker.io credentials to pull-secret in OSP cluster
  shell:
    cmd: |
      set +ex
      eval $(crc oc-env)
      oc get secret/pull-secret -n openshift-config \
        --template='{{ '{{' }} index .data ".dockerconfigjson" | base64decode{{ '}}' }}' \
        >pull-secret.json
      oc registry login --registry="docker.io" \
        --auth-basic="{{ podman_dockerio_user }}:{{ podman_dockerio_password }}" \
        --to=pull-secret.json
      oc set data secret/pull-secret -n openshift-config \
        --from-file=.dockerconfigjson=pull-secret.json
  tags: pull-secret

- name: Deploy openstack operators
  shell:
    cmd: |
      set +ex
      eval $(crc oc-env)
      oc login -u kubeadmin -p 12345678 https://api.crc.testing:6443
      make openstack 2>&1 | tee make_openstack.log
      sleep 10; make openstack_wait; sleep 10
      make openstack_deploy 2>&1 | tee make_openstack_deploy.log
      sleep 10; make openstack_wait_deploy; sleep 10

      oc get csv -n openstack-operators octavia-operator.v0.0.1 -o json | \
        jq -r 'del(.metadata.generation, .metadata.resourceVersion, .metadata.uid)'  > operator_csv.json
      sleep 10
      oc patch csv -n openstack-operators octavia-operator.v0.0.1 --type=json \
        -p="[{'op': 'remove', 'path': '/spec/webhookdefinitions'}]"

      oc project openstack
      oc patch openstackcontrolplane openstack-galera-network-isolation --type=merge --patch '
          spec:
            octavia:
              enabled: true
        '

      oc completion bash | sudo tee /etc/bash_completion.d/oc_completion
      openstack complete | sudo tee /etc/bash_completion.d/osc.bash_completion
      exit 0
    #creates: "/etc/bash_completion.d/oc_completion"
    chdir: "~/install_yamls"
  tags: crc

- name: Add exports to .bashrc
  lineinfile:
    path: ~/.bashrc
    line: "{{ item }}"
  with_items:
    - export PATH=$PATH:~/.crc/bin/oc
    - export OS_CLOUD=default
    - export OS_PASSWORD=12345678
    - export EDPM_COMPUTE_CEPH_ENABLED=false
    - export BMO_SETUP=false
    - export KUBECONFIG=~/.kube/config
  tags: config

- name: Copy ~/.tmux.conf
  copy:
    src: ~/.tmux.conf
    dest: ~/.tmux.conf
    force: no
  ignore_errors: true
  tags: config

- name: Copy ~/.vscode jsons
  copy:
    src: "{{ item }}"
    dest: ~/.vscode/
    force: no
  with_items:
    - launch.json
    - tasks.json
  tags: config

- name: Copy VSCode workspace config
  copy:
    src: stack.code-workspace
    dest: ~/
    force: no
  tags: config

- name: Increase max_user_watches for VSCode
  become: yes
  lineinfile:
    path: /etc/sysctl.conf
    line: fs.inotify.max_user_watches=524288
  notify: "Apply sysctl"
  tags: config

- name: Copy PodSet CR with containerImage fields set
  copy:
    src: octavia_v1beta1_octavia.yaml
    dest: ~/octavia_v1beta1_octavia.yaml
    force: no
  tags: config

# Now run the operator as a Go program locally (outside the Kubernetes cluster):
#
# First run kubefwd in the background so communication between local operator
# and cluster is possible:
# sudo -E kubefwd services -n openstack &
#
# Either using VSCode or directly in a shell:
# In VSCode open the home folder and add the ~/octavia_operator folder to the
# workspace (File->Add folder to workspace...). Then open
# ~/octavia_operator/main.go and press F5 to start the debugger
# In shell:
# cd ~/octavia-operator; ENABLE_WEBHOOKS=false GOWORK= OPERATOR_TEMPLATES=./templates make install run
#
# Deploy your PodSet Custom Resource to the live OpenShift Cluster:
# oc apply -f ~/octavia_v1beta1_octavia.yaml
# watch octavia pods get created using `oc get pods -w`
